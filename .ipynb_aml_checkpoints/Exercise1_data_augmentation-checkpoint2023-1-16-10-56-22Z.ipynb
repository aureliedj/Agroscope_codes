{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "The idea of data augmentation is to create additional training examples by applying sensible modifications to the data you have.\n",
        "\n",
        "## Set up\n",
        "\n",
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670323531786
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install imgaug pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670854864247
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "from utils import DataAugClass, plotAugmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Apply augmentation\n",
        "\n",
        "Transforms are common image transformations available in the `torchvision.transforms` module. However, these transforms are not optimal when dealing with segmentation maps.\n",
        "\n",
        "[Imgaug](https://imgaug.readthedocs.io/en/latest/) is a library for image augmentation in machine learning experiments. It supports a wide range of augmentation techniques, allows to easily combine these and to execute them in random order or on multiple CPU cores, has a simple yet powerful stochastic interface and can not only augment images, but also keypoints/landmarks, bounding boxes, heatmaps and segmentation maps.\n",
        "\n",
        "Another Python library commonly used is [Albumentations](https://albumentations.ai/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670854931453
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define the directory paths where the images and the masks are saved\n",
        "root = os.getcwd()\n",
        "img_dir = root + '/output/viz_aug'\n",
        "mask_dir = root + '/output/viz_aug'\n",
        "\n",
        "# Load the filenames of the images to be augmented\n",
        "csv_file = pd.read_csv(root + '/dataset/aug_dataset.csv').values\n",
        "\n",
        "# Number of new images to be produced\n",
        "N = 5\n",
        "\n",
        "aug_data = DataAugClass(csv_file, img_dir, mask_dir)\n",
        "\n",
        "\n",
        "\n",
        "print('Image filenames \\n', csv_file)\n",
        "print('Number of new images and masks to be produced:', N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670854938865
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def augment(image, segmap, n):\n",
        "\n",
        "    \"\"\"\n",
        "    Applies augmentation on an image and its mask to produce N new images and masks.\n",
        "\n",
        "    Args:\n",
        "            - image: PIL image.\n",
        "            - segmap: object representing a segmentation map associated with the image.\n",
        "            \n",
        "    Outputs:\n",
        "            - augmented\n",
        "    \"\"\"\n",
        "        \n",
        "    sometimes = lambda x: iaa.Sometimes(0.5, x)\n",
        "    seq = iaa.Sequential(\n",
        "                [\n",
        "                    # apply the following augmenters to most images\n",
        "                    iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "                    iaa.Flipud(0.5), # vertically flip 50% of all images\n",
        "                    \n",
        "                    sometimes(iaa.Affine(\n",
        "                        rotate=(-45,45), # rotate by 45 to 135 degrees\n",
        "                        order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                    )),\n",
        "\n",
        "                    sometimes(iaa.Affine(scale=(0.5, 1.5))), #rescale from 50% (zoom in) ton 150% (zoom out)\n",
        "\n",
        "                    # execute 0 to 3 of the following (less important) augmenters per image\n",
        "                    # don't execute all of them, as that would often be way too strong\n",
        "                    iaa.SomeOf((0, 3),\n",
        "                        [\n",
        "                            iaa.GaussianBlur((0, 1.3)), # blur images with a sigma between 0 and 3.0\n",
        "                            iaa.WithBrightnessChannels(iaa.Add((-70, 50))), # change brightness of images (by -10 to 10 of original value)          \n",
        "                            iaa.AdditiveGaussianNoise(scale=(0.05*255, 0.1*255)), #add Gaussian noise\n",
        "                            # either change the brightness of the whole image (sometimes\n",
        "                            \n",
        "                            # per channel) or change the brightness of subareas\n",
        "                            iaa.LinearContrast((0.8, 1.1)), # improve or worsen the contrast\n",
        "                        ],\n",
        "                        random_order=False\n",
        "                    )\n",
        "                ],\n",
        "                random_order=False\n",
        "        )\n",
        "\n",
        "    augmented = [seq(image=image, segmentation_maps=segmap) for _ in range(n)]\n",
        "    return augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670854947210
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "for f in tqdm(aug_data.filenames):\n",
        "            \n",
        "    print('Processing image ', f,' ...')\n",
        "\n",
        "    # Get full input path    \n",
        "    imgPath = glob(aug_data.img_dir + '/cropped_' + f + '*')[0]\n",
        "    maskPath = glob(aug_data.mask_dir + '/' + f + '*')[0]\n",
        "\n",
        "    # Load the image and the mask as PIL image and segmap            \n",
        "    image, segmap = aug_data.getImMk(imgPath, maskPath)\n",
        "\n",
        "    # Apply the augmentation\n",
        "    augmented = augment(image, segmap, N)\n",
        "\n",
        "    # Save the results       \n",
        "    aug_data.saveResults(augmented, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670854950521
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#Show example of the augmentation\n",
        "img_paths = glob(img_dir + '/crop*')\n",
        "plotAugmentation(img_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670854952608
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "msk_paths = glob(img_dir + '/19*')\n",
        "plotAugmentation(msk_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 3. Do it yourself\n",
        "\n",
        "Now, let's see if you can apply your own data augmentation on the training dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define the directory paths where the images and the masks are saved\n",
        "root = os.getcwd()\n",
        "img_dir =  # YOUR CODE HERE\n",
        "mask_dir = # YOUR CODE HERE\n",
        "\n",
        "# Load the filenames of the images to be augmented\n",
        "csv_file = # YOUR CODE HERE\n",
        "\n",
        "# Define number of images to be produced\n",
        "N = # YOUR CODE HERE\n",
        "\n",
        "aug_data = # YOUR CODE HERE\n",
        "\n",
        "print('Image filenames \\n', csv_file)\n",
        "print('Number of new images and masks to be produced:', N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Complete `myCustomAugment` to define your own sequence of augmentations to apply for training the model.\n",
        "\n",
        "If you want to introduce new transforms [here](https://imgaug.readthedocs.io/en/latest/source/overview_of_augmenters.html) are some more examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def myCustomAugment(image, segmap, n):\n",
        "\n",
        "    \"\"\"\n",
        "    Applies augmentation on an image and its mask to produce N new images and masks.\n",
        "\n",
        "    Args:\n",
        "            - image: PIL image.\n",
        "            - segmap: object representing a segmentation map associated with the image.\n",
        "            \n",
        "    Outputs:\n",
        "            - augmented\n",
        "    \"\"\"\n",
        "        \n",
        "    sometimes = lambda x: iaa.Sometimes(0.5, x)\n",
        "    seq = iaa.Sequential(\n",
        "                [   \n",
        "                    # \n",
        "                    # YOUR CODE HERE\n",
        "                    # \n",
        "\n",
        "                ],\n",
        "                random_order=False\n",
        "        )\n",
        "\n",
        "    augmented = [seq(image=image, segmentation_maps=segmap) for _ in range(n)]\n",
        "    return augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "for f in tqdm(aug_data.filenames):\n",
        "            \n",
        "    print('Processing image ', f,' ...')\n",
        "\n",
        "    # Get full input path    \n",
        "    imgPath = glob(aug_data.img_dir + '/cropped_' + f + '*')[0]\n",
        "    maskPath = glob(aug_data.mask_dir + '/' + f + '*')[0]\n",
        "\n",
        "    # Load the image and the mask as PIL image and segmap            \n",
        "    image, segmap = #YOUR CODE HERE\n",
        "\n",
        "    # Apply the augmentation\n",
        "    augmented = # YOUR CODE HERE\n",
        "\n",
        "    # Save the results       \n",
        "    # YOUR CODE HERE"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
